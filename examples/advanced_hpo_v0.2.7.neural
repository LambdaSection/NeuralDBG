network AdvancedHPOExample {
  input: (28, 28, 1)
  layers:
    # Conv2D with HPO for filters, kernel_size, and padding
    Conv2D(
      filters=HPO(choice(32, 64)),
      kernel_size=HPO(choice((3,3), (5,5))),
      padding=HPO(choice("same", "valid")),
      activation="relu"
    )
    MaxPooling2D(pool_size=(2,2))
    
    # Another conv block with HPO
    Conv2D(
      filters=HPO(choice(64, 128)),
      kernel_size=HPO(choice((3,3), (5,5))),
      padding="same",
      activation="relu"
    )
    MaxPooling2D(pool_size=(2,2))
    
    # Flatten and dense layers
    Flatten()
    Dense(HPO(choice(128, 256, 512)), activation="relu")
    Dropout(HPO(range(0.3, 0.7, step=0.1)))
    Output(10, "softmax")
  
  # Advanced optimizer configuration with HPO
  optimizer: Adam(
    learning_rate=ExponentialDecay(
      HPO(log_range(1e-3, 1e-1)),       # Initial learning rate
      HPO(choice(500, 1000, 2000)),      # Variable decay steps
      HPO(range(0.9, 0.99, step=0.01))   # Decay rate
    )
  )
  
  loss: "sparse_categorical_crossentropy"
  
  # Training configuration with HPO
  train {
    epochs: 20
    batch_size: HPO(choice(32, 64, 128))
    validation_split: 0.2
    search_method: "bayesian"  # Use Bayesian optimization
  }
}
