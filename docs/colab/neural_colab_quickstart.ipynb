{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural DSL on Google Colab - Quick Start\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Lemniscate-world/Neural/blob/main/docs/colab/neural_colab_quickstart.ipynb)\n",
        "\n",
        "This notebook demonstrates how to use Neural DSL in Google Colab for rapid prototyping and model development.\n",
        "\n",
        "## Features\n",
        "\n",
        "- ðŸš€ Quick setup (< 2 minutes)\n",
        "- ðŸŽ¯ Define models with simple DSL syntax\n",
        "- ðŸ”„ Compile to TensorFlow, PyTorch, or ONNX\n",
        "- ðŸ“Š Visualize model architectures\n",
        "- ðŸ› Debug models with NeuralDbg dashboard\n",
        "- âš¡ GPU acceleration support\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1ï¸âƒ£ Installation\n",
        "\n",
        "Install Neural DSL from GitHub (takes ~30 seconds):"
      ],
      "metadata": {
        "id": "installation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Neural DSL\n",
        "!pip install -q git+https://github.com/Lemniscate-world/Neural.git\n",
        "\n",
        "# Verify installation\n",
        "import neural\n",
        "print(f\"âœ… Neural DSL v{neural.__version__} installed successfully!\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2ï¸âƒ£ Environment Setup\n",
        "\n",
        "Initialize the Neural cloud executor for Colab:"
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neural.cloud.cloud_execution import CloudExecutor\n",
        "import os\n",
        "\n",
        "# Initialize the cloud executor\n",
        "executor = CloudExecutor()\n",
        "\n",
        "# Display environment info\n",
        "print(f\"Platform: {executor.environment}\")\n",
        "print(f\"GPU Available: {executor.is_gpu_available}\")\n",
        "print(f\"Working Directory: {os.getcwd()}\")\n",
        "\n",
        "# Colab-specific optimizations\n",
        "if executor.environment == 'colab':\n",
        "    print(\"\\nâœ¨ Colab optimizations enabled:\")\n",
        "    print(\"  - GPU memory growth: Enabled\")\n",
        "    print(\"  - TensorFlow logging: Optimized\")\n",
        "    print(\"  - CUDA caching: Configured\")"
      ],
      "metadata": {
        "id": "setup_env"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3ï¸âƒ£ Define Your Model\n",
        "\n",
        "Use Neural DSL to define a simple CNN for MNIST:"
      ],
      "metadata": {
        "id": "define"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple MNIST classifier\n",
        "dsl_code = \"\"\"\n",
        "network MnistCNN {\n",
        "    input: (28, 28, 1)\n",
        "    \n",
        "    layers:\n",
        "        Conv2D(32, (3, 3), \"relu\")\n",
        "        MaxPooling2D((2, 2))\n",
        "        Conv2D(64, (3, 3), \"relu\")\n",
        "        MaxPooling2D((2, 2))\n",
        "        Flatten()\n",
        "        Dense(128, \"relu\")\n",
        "        Dropout(0.5)\n",
        "        Dense(10, \"softmax\")\n",
        "    \n",
        "    loss: \"categorical_crossentropy\"\n",
        "    optimizer: Adam(learning_rate=0.001)\n",
        "    \n",
        "    train {\n",
        "        epochs: 5\n",
        "        batch_size: 64\n",
        "        validation_split: 0.2\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Model defined:\")\n",
        "print(dsl_code)"
      ],
      "metadata": {
        "id": "define_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4ï¸âƒ£ Visualize Architecture\n",
        "\n",
        "Generate a visual representation of your model:"
      ],
      "metadata": {
        "id": "visualize"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Visualize the model architecture\n",
        "viz_path = executor.visualize_model(dsl_code, output_format='png')\n",
        "print(f\"âœ… Visualization saved to: {viz_path}\")\n",
        "\n",
        "# Display in Colab\n",
        "display(Image(filename=viz_path))"
      ],
      "metadata": {
        "id": "visualize_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5ï¸âƒ£ Compile Model\n",
        "\n",
        "Compile the DSL code to TensorFlow:"
      ],
      "metadata": {
        "id": "compile"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile to TensorFlow\n",
        "model_path = executor.compile_model(dsl_code, backend='tensorflow')\n",
        "print(f\"âœ… Model compiled to: {model_path}\")\n",
        "\n",
        "# Display generated code (first 50 lines)\n",
        "print(\"\\nðŸ“ Generated code preview:\")\n",
        "print(\"=\" * 50)\n",
        "with open(model_path, 'r') as f:\n",
        "    lines = f.readlines()[:50]\n",
        "    print(''.join(lines))\n",
        "    if len(lines) == 50:\n",
        "        print(\"\\n... (truncated)\")"
      ],
      "metadata": {
        "id": "compile_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6ï¸âƒ£ Train Model\n",
        "\n",
        "Train the model on MNIST dataset:"
      ],
      "metadata": {
        "id": "train"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model training\n",
        "results = executor.run_model(\n",
        "    model_path,\n",
        "    dataset='MNIST',\n",
        "    epochs=5,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Training completed!\")\n",
        "print(f\"Final accuracy: {results.get('final_accuracy', 'N/A')}\")\n",
        "print(f\"Training time: {results.get('training_time', 'N/A')}s\")\n",
        "\n",
        "# Display full results\n",
        "print(\"\\nðŸ“Š Full results:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "id": "train_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7ï¸âƒ£ Debug with NeuralDbg (Optional)\n",
        "\n",
        "Launch the NeuralDbg dashboard for real-time debugging:\n",
        "\n",
        "**Note:** The dashboard will be accessible via ngrok tunnel (public URL)."
      ],
      "metadata": {
        "id": "debug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start NeuralDbg dashboard with ngrok tunnel\n",
        "# This creates a public URL you can access from anywhere\n",
        "\n",
        "dashboard_info = executor.start_debug_dashboard(\n",
        "    dsl_code,\n",
        "    backend='tensorflow',\n",
        "    setup_tunnel=True\n",
        ")\n",
        "\n",
        "print(\"ðŸ› NeuralDbg Dashboard:\")\n",
        "print(f\"  Local URL: {dashboard_info['dashboard_url']}\")\n",
        "if dashboard_info.get('tunnel_url'):\n",
        "    print(f\"  Public URL: {dashboard_info['tunnel_url']}\")\n",
        "    print(f\"\\nðŸŒ Access your dashboard at: {dashboard_info['tunnel_url']}\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Features:\")\n",
        "print(\"  - Real-time execution traces\")\n",
        "print(\"  - Gradient flow visualization\")\n",
        "print(\"  - Memory profiling\")\n",
        "print(\"  - Dead neuron detection\")\n",
        "print(\"  - Anomaly detection\")"
      ],
      "metadata": {
        "id": "debug_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8ï¸âƒ£ Try Different Backends\n",
        "\n",
        "Compile the same model to PyTorch:"
      ],
      "metadata": {
        "id": "backends"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile to PyTorch\n",
        "pytorch_model_path = executor.compile_model(dsl_code, backend='pytorch')\n",
        "print(f\"âœ… PyTorch model compiled to: {pytorch_model_path}\")\n",
        "\n",
        "# Display generated PyTorch code (first 50 lines)\n",
        "print(\"\\nðŸ“ PyTorch code preview:\")\n",
        "print(\"=\" * 50)\n",
        "with open(pytorch_model_path, 'r') as f:\n",
        "    lines = f.readlines()[:50]\n",
        "    print(''.join(lines))\n",
        "    if len(lines) == 50:\n",
        "        print(\"\\n... (truncated)\")"
      ],
      "metadata": {
        "id": "pytorch_backend"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9ï¸âƒ£ Advanced: Custom Model\n",
        "\n",
        "Try a more complex model with ResNet-style skip connections:"
      ],
      "metadata": {
        "id": "advanced"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a ResNet-inspired model\n",
        "advanced_dsl = \"\"\"\n",
        "network ResNetStyle {\n",
        "    input: (32, 32, 3)\n",
        "    \n",
        "    layers:\n",
        "        Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
        "        BatchNormalization()\n",
        "        \n",
        "        # Residual block\n",
        "        ResidualBlock {\n",
        "            Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
        "            BatchNormalization()\n",
        "            Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
        "            BatchNormalization()\n",
        "        }\n",
        "        \n",
        "        MaxPooling2D((2, 2))\n",
        "        \n",
        "        # Another residual block\n",
        "        ResidualBlock {\n",
        "            Conv2D(128, (3, 3), \"relu\", padding=\"same\")\n",
        "            BatchNormalization()\n",
        "            Conv2D(128, (3, 3), \"relu\", padding=\"same\")\n",
        "            BatchNormalization()\n",
        "        }\n",
        "        \n",
        "        GlobalAveragePooling2D()\n",
        "        Dense(256, \"relu\")\n",
        "        Dropout(0.5)\n",
        "        Dense(10, \"softmax\")\n",
        "    \n",
        "    loss: \"categorical_crossentropy\"\n",
        "    optimizer: Adam(learning_rate=0.001)\n",
        "    \n",
        "    train {\n",
        "        epochs: 10\n",
        "        batch_size: 32\n",
        "        validation_split: 0.2\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Advanced model defined\")\n",
        "\n",
        "# Visualize the advanced model\n",
        "advanced_viz_path = executor.visualize_model(advanced_dsl, output_format='png')\n",
        "print(f\"âœ… Visualization saved to: {advanced_viz_path}\")\n",
        "\n",
        "# Display in Colab\n",
        "display(Image(filename=advanced_viz_path))"
      ],
      "metadata": {
        "id": "advanced_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”Ÿ Cleanup\n",
        "\n",
        "Stop any running processes and clean up:"
      ],
      "metadata": {
        "id": "cleanup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleanup resources\n",
        "executor.cleanup()\n",
        "print(\"âœ… Cleanup completed\")\n",
        "\n",
        "# Optional: Remove temporary files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "temp_dir = '/tmp/neural_temp'\n",
        "if os.path.exists(temp_dir):\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(f\"âœ… Removed temporary directory: {temp_dir}\")"
      ],
      "metadata": {
        "id": "cleanup_resources"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š Next Steps\n",
        "\n",
        "Explore more features:\n",
        "\n",
        "1. **Hyperparameter Optimization**: Use `neural.hpo` for automated HPO with Optuna\n",
        "2. **AutoML**: Try `neural.automl` for Neural Architecture Search\n",
        "3. **Deployment**: Export models to ONNX, TFLite, or TorchScript\n",
        "4. **Monitoring**: Use `neural.monitoring` for production model monitoring\n",
        "5. **Collaboration**: Share models via `neural.marketplace`\n",
        "\n",
        "### Documentation\n",
        "\n",
        "- [Full Documentation](https://neural-dsl.readthedocs.io)\n",
        "- [GitHub Repository](https://github.com/Lemniscate-world/Neural)\n",
        "- [DSL Language Guide](https://github.com/Lemniscate-world/Neural/blob/main/docs/dsl.md)\n",
        "- [Deployment Guide](https://github.com/Lemniscate-world/Neural/blob/main/docs/deployment.md)\n",
        "\n",
        "### Community\n",
        "\n",
        "- [Discord Server](https://discord.gg/KFku4KvS)\n",
        "- [GitHub Discussions](https://github.com/Lemniscate-world/Neural/discussions)\n",
        "- [Twitter](https://x.com/NLang4438)\n",
        "\n",
        "---\n",
        "\n",
        "**Happy modeling! ðŸš€**"
      ],
      "metadata": {
        "id": "next_steps"
      }
    }
  ]
}
