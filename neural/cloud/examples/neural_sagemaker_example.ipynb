{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural DSL on AWS SageMaker\n",
    "\n",
    "This notebook demonstrates how to use Neural DSL in AWS SageMaker environments for production-grade machine learning workflows.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [SageMaker Configuration](#sagemaker-config)\n",
    "3. [Model Development](#model-dev)\n",
    "4. [Distributed Training](#distributed)\n",
    "5. [Model Deployment](#deployment)\n",
    "6. [Cleanup](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Neural DSL\n",
    "!pip install -q git+https://github.com/Lemniscate-SHA-256/Neural.git\n",
    "\n",
    "# Install SageMaker SDK\n",
    "!pip install -q sagemaker boto3\n",
    "\n",
    "print(\"✓ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SageMaker Configuration <a id='sagemaker-config'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from neural.cloud.cloud_execution import CloudExecutor\n",
    "\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "# Initialize Neural DSL executor\n",
    "executor = CloudExecutor(timeout=1200, retry_attempts=3)\n",
    "\n",
    "env_info = executor.get_environment_info()\n",
    "print(f\"\\nEnvironment: {env_info['environment']}\")\n",
    "print(f\"GPU Available: {env_info['gpu_available']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development <a id='model-dev'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define production-ready model\n",
    "production_model = \"\"\"\n",
    "network ProductionCNN {\n",
    "    input: (224, 224, 3)\n",
    "    layers:\n",
    "        Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        MaxPooling2D((2, 2))\n",
    "        \n",
    "        Conv2D(128, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        Conv2D(128, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        MaxPooling2D((2, 2))\n",
    "        \n",
    "        Conv2D(256, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        Conv2D(256, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        GlobalAveragePooling2D()\n",
    "        \n",
    "        Dense(512, \"relu\")\n",
    "        Dropout(0.5)\n",
    "        Dense(1000, \"softmax\")\n",
    "    loss: \"categorical_crossentropy\"\n",
    "    optimizer: Adam(learning_rate=0.001)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile model\n",
    "model_path = executor.compile_model(\n",
    "    production_model,\n",
    "    backend='tensorflow',\n",
    "    output_file='/opt/ml/model/production_model.py'\n",
    ")\n",
    "\n",
    "print(f\"✓ Model compiled: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distributed Training <a id='distributed'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Configure distributed training\n",
    "distributed_config = {\n",
    "    'instance_type': 'ml.p3.2xlarge',\n",
    "    'instance_count': 2,\n",
    "    'distribution': {\n",
    "        'parameter_server': {\n",
    "            'enabled': True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Distributed Training Configuration:\")\n",
    "print(json.dumps(distributed_config, indent=2))\n",
    "print(\"\\n✓ Configuration ready for SageMaker training job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Deployment <a id='deployment'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment configuration\n",
    "deployment_config = {\n",
    "    'endpoint_name': 'neural-dsl-endpoint',\n",
    "    'instance_type': 'ml.m5.xlarge',\n",
    "    'initial_instance_count': 1,\n",
    "    'model_data': model_path\n",
    "}\n",
    "\n",
    "print(\"Deployment Configuration:\")\n",
    "print(json.dumps(deployment_config, indent=2))\n",
    "print(\"\\n✓ Ready for deployment to SageMaker endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup <a id='cleanup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup resources\n",
    "executor.cleanup()\n",
    "print(\"✓ Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
