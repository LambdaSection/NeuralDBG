{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural DSL on Kaggle - Comprehensive Tutorial\n",
    "\n",
    "This notebook demonstrates how to use Neural DSL in Kaggle environments with advanced features, error handling, and cloud optimizations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Installation](#installation)\n",
    "2. [Environment Setup](#environment-setup)\n",
    "3. [Basic Model Compilation](#basic-model-compilation)\n",
    "4. [Model Training](#model-training)\n",
    "5. [Model Visualization](#model-visualization)\n",
    "6. [Advanced Features](#advanced-features)\n",
    "7. [Error Handling](#error-handling)\n",
    "8. [Cloud Optimizations](#cloud-optimizations)\n",
    "9. [Interactive Debugging](#interactive-debugging)\n",
    "10. [Cleanup](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation <a id='installation'></a>\n",
    "\n",
    "First, we need to install Neural DSL. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Neural DSL\n",
    "!pip install -q git+https://github.com/Lemniscate-SHA-256/Neural.git\n",
    "\n",
    "# Install optional dependencies for cloud features\n",
    "!pip install -q pyngrok\n",
    "\n",
    "print(\"✓ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup <a id='environment-setup'></a>\n",
    "\n",
    "Let's initialize the cloud executor and check our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from neural.cloud.cloud_execution import CloudExecutor\n",
    "\n",
    "\n",
    "# Initialize with custom settings\n",
    "executor = CloudExecutor(\n",
    "    timeout=600,  # 10 minutes timeout\n",
    "    retry_attempts=3  # Retry failed operations 3 times\n",
    ")\n",
    "\n",
    "# Get comprehensive environment information\n",
    "env_info = executor.get_environment_info()\n",
    "print(\"Environment Information:\")\n",
    "print(json.dumps(env_info, indent=2))\n",
    "\n",
    "print(f\"\\n✓ Detected environment: {executor.environment}\")\n",
    "print(f\"✓ GPU available: {executor.is_gpu_available}\")\n",
    "print(f\"✓ Optimization level: {executor.optimization_level}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Model Compilation <a id='basic-model-compilation'></a>\n",
    "\n",
    "Let's define and compile a simple CNN model for MNIST classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Neural DSL model\n",
    "dsl_code = \"\"\"\n",
    "network MnistCNN {\n",
    "    input: (28, 28, 1)\n",
    "    layers:\n",
    "        Conv2D(32, (3, 3), \"relu\")\n",
    "        MaxPooling2D((2, 2))\n",
    "        Conv2D(64, (3, 3), \"relu\")\n",
    "        MaxPooling2D((2, 2))\n",
    "        Flatten()\n",
    "        Dense(128, \"relu\")\n",
    "        Dropout(0.5)\n",
    "        Dense(10, \"softmax\")\n",
    "    loss: \"categorical_crossentropy\"\n",
    "    optimizer: Adam(learning_rate=0.001)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Model Definition:\")\n",
    "print(dsl_code)\n",
    "\n",
    "# Compile to TensorFlow with validation\n",
    "try:\n",
    "    tf_model_path = executor.compile_model(\n",
    "        dsl_code, \n",
    "        backend='tensorflow',\n",
    "        validate=True\n",
    "    )\n",
    "    print(f\"\\n✓ Model compiled successfully to: {tf_model_path}\")\n",
    "    \n",
    "    # Display first 50 lines of generated code\n",
    "    with open(tf_model_path, 'r') as f:\n",
    "        lines = f.readlines()[:50]\n",
    "        print(\"\\nGenerated Code (first 50 lines):\")\n",
    "        print(''.join(lines))\n",
    "        if len(f.readlines()) > 50:\n",
    "            print(\"\\n... (truncated)\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"✗ Compilation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training <a id='model-training'></a>\n",
    "\n",
    "Now let's run the compiled model with custom training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with error handling\n",
    "results = executor.run_model(\n",
    "    tf_model_path,\n",
    "    dataset='MNIST',\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    timeout=300  # 5 minutes timeout\n",
    ")\n",
    "\n",
    "# Check results\n",
    "if results['success']:\n",
    "    print(\"✓ Model execution successful!\")\n",
    "    print(\"\\nOutput:\")\n",
    "    print(results['stdout'])\n",
    "else:\n",
    "    print(f\"✗ Model execution failed: {results['error']}\")\n",
    "    print(f\"Error type: {results.get('error_type', 'unknown')}\")\n",
    "    if results.get('stderr'):\n",
    "        print(f\"\\nError details:\\n{results['stderr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Visualization <a id='model-visualization'></a>\n",
    "\n",
    "Visualize the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Generate visualization\n",
    "    viz_path = executor.visualize_model(dsl_code, output_format='png')\n",
    "    print(f\"✓ Visualization saved to: {viz_path}\")\n",
    "    \n",
    "    # Display the visualization\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=viz_path))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Visualization failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Features <a id='advanced-features'></a>\n",
    "\n",
    "### 6.1 Multi-Backend Compilation\n",
    "\n",
    "Compile the same model to different backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = ['tensorflow', 'pytorch']\n",
    "compiled_models = {}\n",
    "\n",
    "for backend in backends:\n",
    "    try:\n",
    "        model_path = executor.compile_model(dsl_code, backend=backend)\n",
    "        compiled_models[backend] = model_path\n",
    "        print(f\"✓ {backend.capitalize()} compilation successful: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {backend.capitalize()} compilation failed: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully compiled to {len(compiled_models)} backend(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Complex Model with Residual Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more complex model\n",
    "complex_dsl = \"\"\"\n",
    "network ResNetBlock {\n",
    "    input: (32, 32, 3)\n",
    "    layers:\n",
    "        Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        MaxPooling2D((2, 2))\n",
    "        Dropout(0.25)\n",
    "        \n",
    "        Conv2D(128, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        Conv2D(128, (3, 3), \"relu\", padding=\"same\")\n",
    "        BatchNormalization()\n",
    "        MaxPooling2D((2, 2))\n",
    "        Dropout(0.25)\n",
    "        \n",
    "        GlobalAveragePooling2D()\n",
    "        Dense(256, \"relu\")\n",
    "        Dropout(0.5)\n",
    "        Dense(10, \"softmax\")\n",
    "    loss: \"categorical_crossentropy\"\n",
    "    optimizer: Adam(learning_rate=0.001)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    complex_model_path = executor.compile_model(complex_dsl, backend='tensorflow')\n",
    "    print(f\"✓ Complex model compiled: {complex_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Complex model compilation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Handling <a id='error-handling'></a>\n",
    "\n",
    "Demonstrate robust error handling with intentional errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Empty DSL code\n",
    "print(\"Test 1: Empty DSL code\")\n",
    "try:\n",
    "    executor.compile_model(\"\", backend='tensorflow')\n",
    "    print(\"✗ Should have failed\")\n",
    "except Exception as e:\n",
    "    print(f\"✓ Caught expected error: {type(e).__name__}\")\n",
    "\n",
    "# Test 2: Invalid model file path\n",
    "print(\"\\nTest 2: Non-existent model file\")\n",
    "try:\n",
    "    executor.run_model('/invalid/path/model.py', dataset='MNIST')\n",
    "    print(\"✗ Should have failed\")\n",
    "except Exception as e:\n",
    "    print(f\"✓ Caught expected error: {type(e).__name__}\")\n",
    "\n",
    "# Test 3: Invalid DSL syntax\n",
    "print(\"\\nTest 3: Invalid DSL syntax\")\n",
    "invalid_dsl = \"network Invalid { invalid syntax }\"\n",
    "try:\n",
    "    executor.compile_model(invalid_dsl, backend='tensorflow')\n",
    "    print(\"✗ Should have failed\")\n",
    "except Exception as e:\n",
    "    print(f\"✓ Caught expected error: {type(e).__name__}\")\n",
    "\n",
    "print(\"\\n✓ All error handling tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cloud Optimizations <a id='cloud-optimizations'></a>\n",
    "\n",
    "Neural DSL automatically applies cloud-specific optimizations based on your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Display active optimizations\n",
    "print(\"Active Cloud Optimizations:\")\n",
    "print(f\"- Environment: {executor.environment}\")\n",
    "print(f\"- Optimization Level: {executor.optimization_level}\")\n",
    "print(f\"- GPU Memory Growth: {os.environ.get('TF_FORCE_GPU_ALLOW_GROWTH', 'not set')}\")\n",
    "print(f\"- TensorFlow Log Level: {os.environ.get('TF_CPP_MIN_LOG_LEVEL', 'not set')}\")\n",
    "print(f\"- PyTorch CUDA Allocation: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF', 'not set')}\")\n",
    "print(f\"- Unbuffered Python Output: {os.environ.get('PYTHONUNBUFFERED', 'not set')}\")\n",
    "\n",
    "if executor.is_gpu_available:\n",
    "    print(\"\\n✓ GPU optimizations enabled\")\n",
    "else:\n",
    "    print(\"\\n✓ CPU optimizations enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interactive Debugging <a id='interactive-debugging'></a>\n",
    "\n",
    "Start the NeuralDbg dashboard with an ngrok tunnel for remote access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the dashboard (optional - requires ngrok)\n",
    "try:\n",
    "    dashboard_info = executor.start_debug_dashboard(\n",
    "        dsl_code,\n",
    "        backend='tensorflow',\n",
    "        setup_tunnel=True,\n",
    "        port=8050\n",
    "    )\n",
    "    \n",
    "    if dashboard_info['status'] == 'running':\n",
    "        print(\"✓ Dashboard started successfully\")\n",
    "        print(f\"Dashboard URL: {dashboard_info['dashboard_url']}\")\n",
    "        print(f\"Tunnel URL: {dashboard_info['tunnel_url']}\")\n",
    "        print(f\"Process ID: {dashboard_info['process_id']}\")\n",
    "        \n",
    "        # Display a clickable link\n",
    "        from IPython.display import HTML, display\n",
    "        display(HTML(f\"<a href='{dashboard_info['tunnel_url']}' target='_blank'>Open NeuralDbg Dashboard</a>\"))\n",
    "    else:\n",
    "        print(f\"✗ Dashboard failed to start: {dashboard_info.get('error', 'Unknown error')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Could not start dashboard: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start No-Code Interface\n",
    "\n",
    "Launch the Neural No-Code interface for visual model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the No-Code interface (optional)\n",
    "try:\n",
    "    nocode_info = executor.start_nocode_interface(\n",
    "        port=8051,\n",
    "        setup_tunnel=True\n",
    "    )\n",
    "    \n",
    "    if nocode_info['status'] == 'running':\n",
    "        print(\"✓ No-Code interface started successfully\")\n",
    "        print(f\"Interface URL: {nocode_info['interface_url']}\")\n",
    "        print(f\"Tunnel URL: {nocode_info['tunnel_url']}\")\n",
    "        \n",
    "        # Display a clickable link\n",
    "        from IPython.display import HTML, display\n",
    "        display(HTML(f\"<a href='{nocode_info['tunnel_url']}' target='_blank'>Open Neural No-Code Interface</a>\"))\n",
    "    else:\n",
    "        print(f\"✗ No-Code interface failed to start: {nocode_info.get('error', 'Unknown error')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Could not start No-Code interface: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup <a id='cleanup'></a>\n",
    "\n",
    "Clean up temporary files and processes when you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up all resources\n",
    "executor.cleanup()\n",
    "print(\"✓ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. ✓ Install and configure Neural DSL on Kaggle\n",
    "2. ✓ Check environment information and GPU availability\n",
    "3. ✓ Compile Neural DSL models to different backends\n",
    "4. ✓ Train models with custom parameters and error handling\n",
    "5. ✓ Visualize model architectures\n",
    "6. ✓ Use advanced features like multi-backend compilation\n",
    "7. ✓ Handle errors gracefully\n",
    "8. ✓ Leverage cloud-specific optimizations\n",
    "9. ✓ Access debugging dashboards remotely via ngrok\n",
    "10. ✓ Clean up resources properly\n",
    "\n",
    "For more information, visit the [Neural DSL documentation](https://github.com/Lemniscate-SHA-256/Neural)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
