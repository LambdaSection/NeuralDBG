---
description: Projets A (Transformer Probabiliste) & B (Adaptive Gradient) — un seul à la fois
alwaysApply: true
---

# Roadmap AntiGravity — Projets A & B

## Règle d'or
**Un seul projet à la fois.** Pas de développement en parallèle. Finir A ou B avant de passer à l'autre.

## Projet A — Transformer Probabiliste (OpenQuant)
- Modéliser \( P(Y_{t+1} \mid X_{1:t}) \) — distribution, pas point estimate
- Archi : embedding + positional + encoder + head (μ, σ)
- Data : **commencer synthétique** (sinusoïde bruitée)
- Loss : NLL Gaussian
- Spec complète : `.antigravity/RULES.md`

## Projet B — Adaptive Gradient (NeuralDBG)
- Couche qui mesure ‖∇W‖, EMA, rescale si gradient < seuil
- `AdaptiveGradientWrapper` encapsule toute couche
- Tester sur MLP profond, RNN, Transformer
- Spec complète : `.antigravity/RULES.md`

## Artifacts
Stocker sous `./.antigravity/artifacts/`.
